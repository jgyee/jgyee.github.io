---
title: "Machine Learning Project: MCA"
date: 2019-06-10
tags: [MCA, Multiple Correspondence Analysis]
header:
  image: "/images/danapointharbor.jpg"
excerpt: "Machine Learning, MCA, Data Science"
mathjax: true
---

# A Case Study in Multiple Correspondence Analysis: Clicker Question Responses to Cluster Different Types of Students

#### *University of California, Los Angeles*
#### Justin Yee
#### June 10, 2019


### Introduction:
For the purposes of this study, the main focus of analysis was to draw insights of the different types of both questions and students from the dataset of clicker question responses registered from an Undergraduate Introductory Statistics course at UCLA. The nature of the dataset led to the main method of statistical analysis – Multiple Correspondence Analysis. Dealing with categorical responses (Multiple Choice Answers), and no labels or semantic meaning behind any of the answer choices given, besides the key to the correct response, clustering methods and data analysis that did not rely on unavailable information were necessary. As such, the analysis of this study distinguishes between only two types of student responses: 1. Student responses that are either identical (Student 1 answering Question 1 with ‘A’ and Student 2 answering Question 1 with ‘A’), or 2. Student responses that are not identical, with each type of non-identical response being given the same ‘weight’ in terms of dissimilarity or distance metric.


### Exploratory Analysis:
To first understand the dataset, exploratory analysis of summary statistics was conducted. To start, I first looked at the summary statistics of the Questions variable, to assess the distribution of Question difficulty, as measured by total percent correct by each question.

![Question Difficulty Distribution](/images/Question Difficulty Combined Plots.png)

As seen by the bar chart and density plot above, the distribution of Question difficulty is slightly skewed left, as most questions had above 50% correct. The summary table below confirms the distribution.

![Question Difficulty Table](/images/Question Difficulty Table.png)

Next, we take a look at the exploratory analysis of the student distribution.

![Student Scores Distribution](/images/Student Scores Combined.png)

Looking at the bar chart and density plot, we can see that the distribution of students’ overall percent correct score is similar to that of the question difficulty distribution (skewed left). The below summary table confirms this similar distribution, although with slightly lower averages than that of the question difficulty distribution.

![Student Scores Table](/images/Student Scores Table.png)

From this exploratory analysis, we can see that while the most common answer by far is the correct answer, there is still much room for improvement in the student answers, and perhaps there are trends and patterns present within students who usually get answers correct versus students who have a lower total percent score. We will explore these patterns further in our analysis and statistical methodologies.

### Multiple Correspondence Analysis:

In hopes of finding distinctive and informative clusters about the different types of students through an unsupervised learning approach, I employed the statistical method of Multiple Correspondence Analysis. Similar in nature to the method of Principle Components Analysis, Multiple Correspondence Analysis is a dimensionality reduction technique that is specifically designed to handle categorical variables as opposed to numeric, continuous variables. Below are the results from the Multiple Correspondence Analysis depicted in the form of a separated biplot. The left MCA factor map in blue displays the individuals (Students), while the right MCA factor map in red displays the variables (Questions).

![MCA factor maps](/images/MCA factor maps.png)

Following this projection of the data into two Principal Components (dimensions), hierarchical clustering was performed to obtain three distinct clusters. We will later dive into the results of these clusters and their interpretations within the context of our dataset.

![Tree cluster](/images/tree cluster.png)

![2d map cluster](/images/factor map cluster.png)

Scree Plot results from the Multiple Correspondence Analysis indicate that the first two dimensions, and the first dimension in particular, capture the variance of the data fairly well (26.11%), considering that there are 97 Questions (dimensions) to start with the original dataset.

![Scree plot](/images/MCA Scree plot.png)

95% confidence ellipses of the first four Questions reveal that the most distinguishing answer type is the “NA” answer choice, which denotes that the student was not accounted for in the clicker question registration. The “NA” answer choice also differs from the “NV” answer choice, as “NV” indicates that the student had registered their clicker, but did not respond to the question, while the “NA” response indicates a student who had not yet registered their clicker.

![Confidence ellipses](/images/Confidence ellipses.png)

Looking at the counts of “NA” responses by Question and by Student (researchID), we get the following results. The distributions for both Questions and Students are left skewed, telling us that most questions and students had registered clicker responders. These results may give us insight into the meaning behing the hierarchical cluster results derived from the Multiple Correspondence Analysis. The analysis of the “NA” response values and the hierarchical clusters may reveal a connection between students who register their clickers later in the quarter and their performance on the questions they answer following their late registration.

![NA Count bar chart](/images/NA Count Combined.png)

When looking at the mean count of “NA” student responses within the context of the clusters produced from the hierarchical clustering algorithm, we see that the “NA” responses have a clear and substantial effect on the creation of the clusters of different types of students. Additionally, when analyzing the density plots of clusters in the context of the students’ Percent Correct score, we see that cluster 1 has higher percent correct students compared to cluster 2 and cluster 3. Therefore, we can deduce that there are definite “types” of students who register their clickers later in the class, thus negatively impacting their performance on clicker questions for the remainder of the quarter.

![Cluster and correlation plots](/images/Combined Cluster plots.png)

To gain further insight into the interpretation of the hierarchical clusters, I derived my own version of a “correlation” matrix for the categorical response variables (Multiple Choice Answers). To do this, I matched up each question and answer while preserving the correct ordering of the question and answers in order to directly compare two students to each other. This “proportion of exactness” ranged from the values 0-1, mimicking the correlation coefficient of numerical variables. While the answer responses themselves have no meaning, outside of the key (correct answer), NV, or NA values, they serve to show if certain students are answering in the same exact way, thus denoting a measurement of similarity. This will output a very large matrix (50 by 50 matrix), since we must compare all students against each other. Since this output is impossible to look at, we will look at the highest “proportion of exactness” coefficient for each row.

I have displayed a table of the results below, denoting cluster 2 pairs in red and cluster 3 pairs in green. The results of the clusters match the highest pairs exactly. Therefore, we can say that the clustered groups also have high “correlation” with each other in terms of answering the same exact ways.

![Proportion Coefficient Table](/images/Proportion Coefficient Table.png)

Now that we have gained some insight into the different types of students, we will turn our attention to the different types of questions. An advantage of this dataset is the labeled question types, in that there are certain questions that are repeated. Questions that the professor deemed more difficult based on the total percentage correct of the students were often repeated. I sought to determine the effect of Repeated Questions on the creation of the Principal Components from the Multiple Correspondence Analysis.

Of the 16 highest contribution variables(Questions) to the first Principal Component, each question having the same amount of contribution, 75% of those questions fell in the category of a Repeated Question. In contrast, Repeated Questions only made up 41% of the total Questions in the dataset. These results indicate that the variation present in the types of Students can be greatly attributed to these Repeated Questions.

![Repeated Questions Bar Chart](/images/Repeated Question Proportions.png)

Another lens to look at the informational value of Repeated Questions is the amount of Shannon’s entropy for each question. Shannon’s entropy increases as the level of uncertainty for a response increases. In other words, Shannon’s entropy is at a maximum when the response variables are distributed uniformly, and at a minimum when only one response variable is observed and the other response variables have a frequency of zero. According to information and psychometric theory, a question is considered to be more valuable for a researcher if the question carries a high value of entropy.

My intuition led me to believe that Repeated Questions might show a significant difference in entropy compared to Non-Repeated Questions, however they did not. However, if we break down the Repeated Questions into three different categories – First Time, First Repeat, and Second Repeat, we can see some noticeable changes in mean entropy levels between these categories. Looking at the bar chart below, the entropies are fairly similar, however the First Time is the highest, followed by the Second Repeat, which is followed by the First Repeat. These entropy levels could signal that the First Time is the most difficult type of question, and there is a significant amount of improvement under the First Repeat. However, the Second Repeat entropy level is greater since only very difficult questions were repeated a second time (2 questions in total).

![Entropy by Repeat Type Bar Chart](/images/Entropy Breakdown by Repeat Type.png)

### Conclusions and Further Studies:

Through statistical analysis of the clicker question dataset, we were able to draw insights from the Multiple Correspondence Analysis, Hierarchical Clustering following the Multiple Correspondence Analysis Principal Components, and Shannon’s Entropy Analysis.

From the Cluster Analysis, we were able to conclude that the “NA” response values play a significant role in the formation of distinct clusters and in the performance of Students in regards to their Percent Correct Score. From this, we can conclude that it is particularly important for Students to register clickers early on in the class and building a strong foundation of statistical knowledge in order to perform well and understand the material going forward.

By creating a “proportion of exactness” and comparing the highest “correlated” pairs of students to the results of the hierarchical clustering, we were able to gain even an additional insight into the interpretation of the clusters from the Multiple Correspondence Analysis. We found that these clusters of students tend to answer questions in the same exact way for many questions, thus giving us a way to group students based on their mode of thinking, if we were to give semantic labels to the question answers retroactively.

Lastly, we looked at the types of Questions in the dataset, Repeated and Non-Repeated, to gain information concerning the performance of Students on different types of Questions. In general, from the measurements of Shannon’s Entropy, we saw that a greater level of consensus was reached when a question was repeated, thus showing the benefits of repeating a question for the students to discuss amongst themselves and try again.

In future studies, we can take a deeper dive into specific questions and specific pairs of students to gain semantic meaning behind the questions and answers by categorizing them beforehand. This study was meant to gain general insight into the different types of students and questions, but more specific conclusions can be reached in future studies.

### References:
Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.1. https://CRAN.R-project.org/package=stargazer    

Sebastien Le, Julie Josse, Francois Husson (2008). FactoMineR: An R Package for Multivariate Analysis. Journal of Statistical Software, 25(1), 1-18. 10.18637/jss.v025.i01
